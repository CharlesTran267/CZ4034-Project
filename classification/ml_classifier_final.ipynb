{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import gensim.downloader\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data = pd.read_csv('data/incomplete_annotations_data2.csv')\n",
    "\n",
    "# annotated_data = full_data[full_data['Subjectivity'].notnull()]\n",
    "# unannotated_data = full_data[full_data['Subjectivity'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subjectivity\n",
       "1.0    1560\n",
       "0.0    1123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data['Subjectivity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polarity\n",
       "1.0    876\n",
       "0.0    684\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data['Polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter-annotation Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source\n",
       "Reddit                                                                                        1024\n",
       "Twitter                                                                                       1016\n",
       "TikTok                                                                                         206\n",
       "Instagram                                                                                      203\n",
       "https://www.youtube.com//watch?v=rYATRV6W4iA&pp=ygUaRm9yZXZlciAyMSBhbmltYWwgdGVzdGluZyA%3D       5\n",
       "                                                                                              ... \n",
       "https://www.youtube.com//watch?v=DiuII_0KvDk&pp=ygURTWFuZ28gY29tcGFyaXNvbiA%3D                   1\n",
       "https://www.youtube.com//watch?v=7CkRsMmrUcI&pp=ygUOVmVyc2FjZSB3YXN0ZSA%3D                       1\n",
       "https://www.youtube.com//watch?v=jcjoIOwnxKA&pp=ygURRGlvciBjb25zdW1lcmlzbSA%3D                   1\n",
       "https://www.youtube.com//watch?v=zBLSn-nLFhM&pp=ygUPTWFuZ28gb3BpbmlvbnMg                         1\n",
       "https://www.youtube.com//watch?v=uTW8pWKhYv8&pp=ygUXRm9yZXZlciAyMSBjb25zdW1lcmlzbSA%3D           1\n",
       "Name: count, Length: 162, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between annotator 1 and annotator 2 for subjectivity labels: 0.8777546356018551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "subjectivity_labels1 = annotated_data['Subjectivity']\n",
    "subjectivity_labels2 = annotated_data['Subjectivity 2']\n",
    "\n",
    "kappa_subjectivity = cohen_kappa_score(subjectivity_labels1, subjectivity_labels2)\n",
    "\n",
    "print(\"Cohen's kappa between annotator 1 and annotator 2 for subjectivity labels:\", kappa_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between annotator 1 and annotator 2 for polarity labels: 0.8582205823592879\n"
     ]
    }
   ],
   "source": [
    "polarity_labels1 = annotated_data['Polarity']\n",
    "polarity_labels2 = annotated_data['Polarity 2']\n",
    "\n",
    "valid_indices = (subjectivity_labels1 == 1) & (subjectivity_labels2 == 1)\n",
    "filtered_original_polarity = polarity_labels1[valid_indices]\n",
    "filtered_new_polarity = polarity_labels2[valid_indices]\n",
    "filtered_new_polarity_numeric = np.array(filtered_new_polarity, dtype=float) \n",
    "\n",
    "kappa_polarity = cohen_kappa_score(filtered_new_polarity_numeric, filtered_original_polarity)\n",
    "\n",
    "print(\"Cohen's kappa between annotator 1 and annotator 2 for polarity labels:\", kappa_polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "- Lowercasing\n",
    "- Removing stopwords\n",
    "- Replacing emoji \n",
    "- Replace slang/abbreviations with their text counterparts\n",
    "\n",
    "<!-- - Mispellings -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Search Term</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Metadata</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity 2</th>\n",
       "      <th>Polarity 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>JW Anderson</td>\n",
       "      <td>JW Anderson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>{'Likes_and_timestamp': '0 likes on 2023-11-20...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand  Search Term Comment     Source  \\\n",
       "2590  JW Anderson  JW Anderson     NaN  Instagram   \n",
       "\n",
       "                                               Metadata  Subjectivity  \\\n",
       "2590  {'Likes_and_timestamp': '0 likes on 2023-11-20...           0.0   \n",
       "\n",
       "      Polarity  Subjectivity 2  Polarity 2  \n",
       "2590       NaN             0.0         NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data[annotated_data['Comment'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand              103\n",
      "Search Term        174\n",
      "Comment              0\n",
      "Source               0\n",
      "Metadata           234\n",
      "Subjectivity         0\n",
      "Polarity          1122\n",
      "Subjectivity 2       0\n",
      "Polarity 2        1140\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "annotated_data = annotated_data.dropna(subset=['Comment'])\n",
    "print(annotated_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ain't\": 'is not', \"aren't\": 'are not', \"can't\": 'cannot', \"can't've\": 'cannot have', \"'cause\": 'because', \"could've\": 'could have', \"couldn't\": 'could not', \"couldn't've\": 'could not have', \"didn't\": 'did not', \"doesn't\": 'does not', \"don't\": 'do not', \"hadn't\": 'had not', \"hadn't've\": 'had not have', \"hasn't\": 'has not', \"haven't\": 'have not', \"he'd\": 'he would', \"he'd've\": 'he would have', \"he'll\": 'he will', \"he'll've\": 'he he will have', \"he's\": 'he is', \"how'd\": 'how did', \"how'd'y\": 'how do you', \"how'll\": 'how will', \"how's\": 'how is', \"I'd\": 'I would', \"I'd've\": 'I would have', \"I'll\": 'I will', \"I'll've\": 'I will have', \"I'm\": 'I am', \"I've\": 'I have', \"i'd\": 'i would', \"i'd've\": 'i would have', \"i'll\": 'i will', \"i'll've\": 'i will have', \"i'm\": 'i am', \"i've\": 'i have', \"isn't\": 'is not', \"it'd\": 'it would', \"it'd've\": 'it would have', \"it'll\": 'it will', \"it'll've\": 'it will have', \"it's\": 'it is', \"let's\": 'let us', \"ma'am\": 'madam', \"mayn't\": 'may not', \"might've\": 'might have', \"mightn't\": 'might not', \"mightn't've\": 'might not have', \"must've\": 'must have', \"mustn't\": 'must not', \"mustn't've\": 'must not have', \"needn't\": 'need not', \"needn't've\": 'need not have', \"o'clock\": 'of the clock', \"oughtn't\": 'ought not', \"oughtn't've\": 'ought not have', \"shan't\": 'shall not', \"sha'n't\": 'shall not', \"shan't've\": 'shall not have', \"she'd\": 'she would', \"she'd've\": 'she would have', \"she'll\": 'she will', \"she'll've\": 'she will have', \"she's\": 'she is', \"should've\": 'should have', \"shouldn't\": 'should not', \"shouldn't've\": 'should not have', \"so've\": 'so have', \"so's\": 'so as', \"that'd\": 'that would', \"that'd've\": 'that would have', \"that's\": 'that is', \"there'd\": 'there would', \"there'd've\": 'there would have', \"there's\": 'there is', \"they'd\": 'they would', \"they'd've\": 'they would have', \"they'll\": 'they will', \"they'll've\": 'they will have', \"they're\": 'they are', \"they've\": 'they have', \"to've\": 'to have', \"wasn't\": 'was not', \"we'd\": 'we would', \"we'd've\": 'we would have', \"we'll\": 'we will', \"we'll've\": 'we will have', \"we're\": 'we are', \"we've\": 'we have', \"weren't\": 'were not', \"what'll\": 'what will', \"what'll've\": 'what will have', \"what're\": 'what are', \"what's\": 'what is', \"what've\": 'what have', \"when's\": 'when is', \"when've\": 'when have', \"where'd\": 'where did', \"where's\": 'where is', \"where've\": 'where have', \"who'll\": 'who will', \"who'll've\": 'who will have', \"who's\": 'who is', \"who've\": 'who have', \"why's\": 'why is', \"why've\": 'why have', \"will've\": 'will have', \"won't\": 'will not', \"won't've\": 'will not have', \"would've\": 'would have', \"wouldn't\": 'would not', \"wouldn't've\": 'would not have', \"y'all\": 'you all', \"y'all'd\": 'you all would', \"y'all'd've\": 'you all would have', \"y'all're\": 'you all are', \"y'all've\": 'you all have', \"you'd\": 'you would', \"you'd've\": 'you would have', \"you'll\": 'you will', \"you'll've\": 'you will have', \"you're\": 'you are', \"you've\": 'you have', '$': ' dollar ', '€': ' euro ', '4ao': 'for adults only', 'a.m': 'before midday', 'a3': 'anytime anywhere anyplace', 'aamof': 'as a matter of fact', 'acct': 'account', 'adih': 'another day in hell', 'afaic': 'as far as i am concerned', 'afaict': 'as far as i can tell', 'afaik': 'as far as i know', 'afair': 'as far as i remember', 'afk': 'away from keyboard', 'app': 'application', 'approx': 'approximately', 'apps': 'applications', 'asap': 'as soon as possible', 'asl': 'age, sex, location', 'atk': 'at the keyboard', 'ave.': 'avenue', 'aymm': 'are you my mother', 'ayor': 'at your own risk', 'b&b': 'bed and breakfast', 'b+b': 'bed and breakfast', 'b.c': 'before christ', 'b2b': 'business to business', 'b2c': 'business to customer', 'b4': 'before', 'b4n': 'bye for now', 'b@u': 'back at you', 'bae': 'before anyone else', 'bak': 'back at keyboard', 'bbbg': 'bye bye be good', 'bbc': 'british broadcasting corporation', 'bbias': 'be back in a second', 'bbl': 'be back later', 'bbs': 'be back soon', 'be4': 'before', 'bfn': 'bye for now', 'blvd': 'boulevard', 'bout': 'about', 'brb': 'be right back', 'bros': 'brothers', 'brt': 'be right there', 'bsaaw': 'big smile and a wink', 'btw': 'by the way', 'bwl': 'bursting with laughter', 'c/o': 'care of', 'cet': 'central european time', 'cf': 'compare', 'cia': 'central intelligence agency', 'csl': 'can not stop laughing', 'cu': 'see you', 'cul8r': 'see you later', 'cv': 'curriculum vitae', 'cwot': 'complete waste of time', 'cya': 'see you', 'cyt': 'see you tomorrow', 'dae': 'does anyone else', 'dbmib': 'do not bother me i am busy', 'diy': 'do it yourself', 'dm': 'direct message', 'dwh': 'during work hours', 'e123': 'easy as one two three', 'eet': 'eastern european time', 'eg': 'example', 'embm': 'early morning business meeting', 'encl': 'enclosed', 'encl.': 'enclosed', 'etc': 'and so on', 'faq': 'frequently asked questions', 'fawc': 'for anyone who cares', 'fb': 'facebook', 'fc': 'fingers crossed', 'fig': 'figure', 'fimh': 'forever in my heart', 'ft.': 'feet', 'ft': 'featuring', 'ftl': 'for the loss', 'ftw': 'for the win', 'fwiw': 'for what it is worth', 'fyi': 'for your information', 'g9': 'genius', 'gahoy': 'get a hold of yourself', 'gal': 'get a life', 'gcse': 'general certificate of secondary education', 'gfn': 'gone for now', 'gg': 'good game', 'gl': 'good luck', 'glhf': 'good luck have fun', 'gmt': 'greenwich mean time', 'gmta': 'great minds think alike', 'gn': 'good night', 'g.o.a.t': 'greatest of all time', 'goat': 'greatest of all time', 'goi': 'get over it', 'gps': 'global positioning system', 'gr8': 'great', 'gratz': 'congratulations', 'gyal': 'girl', 'h&c': 'hot and cold', 'hp': 'horsepower', 'hr': 'hour', 'hrh': 'his royal highness', 'ht': 'height', 'ibrb': 'i will be right back', 'ic': 'i see', 'icq': 'i seek you', 'icymi': 'in case you missed it', 'idc': 'i do not care', 'idgadf': 'i do not give a damn fuck', 'idgaf': 'i do not give a fuck', 'idk': 'i do not know', 'ie': 'that is', 'i.e': 'that is', 'ifyp': 'i feel your pain', 'IG': 'instagram', 'iirc': 'if i remember correctly', 'ilu': 'i love you', 'ily': 'i love you', 'imho': 'in my humble opinion', 'imo': 'in my opinion', 'imu': 'i miss you', 'iow': 'in other words', 'irl': 'in real life', 'j4f': 'just for fun', 'jic': 'just in case', 'jk': 'just kidding', 'jsyk': 'just so you know', 'l8r': 'later', 'lb': 'pound', 'lbs': 'pounds', 'ldr': 'long distance relationship', 'lmao': 'laugh my ass off', 'lmfao': 'laugh my fucking ass off', 'lol': 'laughing out loud', 'ltd': 'limited', 'ltns': 'long time no see', 'm8': 'mate', 'mf': 'motherfucker', 'mfs': 'motherfuckers', 'mfw': 'my face when', 'mofo': 'motherfucker', 'mph': 'miles per hour', 'mr': 'mister', 'mrw': 'my reaction when', 'ms': 'miss', 'mte': 'my thoughts exactly', 'nagi': 'not a good idea', 'nbc': 'national broadcasting company', 'nbd': 'not big deal', 'nfs': 'not for sale', 'ngl': 'not going to lie', 'nhs': 'national health service', 'nrn': 'no reply necessary', 'nsfl': 'not safe for life', 'nsfw': 'not safe for work', 'nth': 'nice to have', 'nvr': 'never', 'nyc': 'new york city', 'oc': 'original content', 'og': 'original', 'ohp': 'overhead projector', 'oic': 'oh i see', 'omdb': 'over my dead body', 'omg': 'oh my god', 'omw': 'on my way', 'p.a': 'per annum', 'p.m': 'after midday', 'pm': 'prime minister', 'poc': 'people of color', 'pov': 'point of view', 'pp': 'pages', 'ppl': 'people', 'prw': 'parents are watching', 'ps': 'postscript', 'pt': 'point', 'ptb': 'please text back', 'pto': 'please turn over', 'qpsa': 'what happens', 'ratchet': 'rude', 'rbtl': 'read between the lines', 'rlrt': 'real life retweet', 'rofl': 'rolling on the floor laughing', 'roflol': 'rolling on the floor laughing out loud', 'rotflmao': 'rolling on the floor laughing my ass off', 'rt': 'retweet', 'ruok': 'are you ok', 'sfw': 'safe for work', 'sk8': 'skate', 'smh': 'shake my head', 'sq': 'square', 'srsly': 'seriously', 'ssdd': 'same stuff different day', 'tbh': 'to be honest', 'tbs': 'tablespooful', 'tbsp': 'tablespooful', 'tfw': 'that feeling when', 'thks': 'thank you', 'tho': 'though', 'thx': 'thank you', 'tia': 'thanks in advance', 'til': 'today i learned', 'tl;dr': 'too long i did not read', 'tldr': 'too long i did not read', 'tmb': 'tweet me back', 'tntl': 'trying not to laugh', 'ttyl': 'talk to you later', 'u': 'you', 'u2': 'you too', 'u4e': 'yours for ever', 'utc': 'coordinated universal time', 'w/': 'with', 'w/o': 'without', 'w8': 'wait', 'wassup': 'what is up', 'wb': 'welcome back', 'wtf': 'what the fuck', 'wtg': 'way to go', 'wtpa': 'where the party at', 'wuf': 'where are you from', 'wuzup': 'what is up', 'wywh': 'wish you were here', 'yd': 'yard', 'ygtr': 'you got that right', 'ynk': 'you never know', 'zzz': 'sleeping bored and tired'}\n"
     ]
    }
   ],
   "source": [
    "with open('abbreviations_list.pkl', 'rb') as file:\n",
    "    abbreviations = pickle.load(file)\n",
    "\n",
    "print(abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating extra column for preprocessed text\n",
    "annotated_data['Preprocessed Comment'] = annotated_data['Comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing emojis\n",
    "import emoji\n",
    "\n",
    "def demojize_with_delimiters(text):\n",
    "    return emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "\n",
    "annotated_data['Preprocessed Comment'] = annotated_data['Preprocessed Comment'].apply(lambda x: demojize_with_delimiters(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤️❤️❤️\n",
      " red_heart  red_heart  red_heart \n"
     ]
    }
   ],
   "source": [
    "# Example of emoji normalisation\n",
    "\n",
    "import emoji\n",
    "\n",
    "def demojize_with_delimiters(text):\n",
    "    return emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "\n",
    "print(annotated_data['Comment'].iloc[2677])\n",
    "print(demojize_with_delimiters(annotated_data['Comment'].iloc[2677]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing\n",
    "\n",
    "annotated_data['Preprocessed Comment'] = annotated_data['Preprocessed Comment'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Removing stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Ensure the input is a string\n",
    "    if isinstance(text, str):\n",
    "        # Tokenize the text into words\n",
    "        words = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Get the list of stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # Remove stopwords from the tokenized words\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "        \n",
    "        # Join the filtered words back into a single string\n",
    "        filtered_text = ' '.join(filtered_words)\n",
    "        \n",
    "        return filtered_text\n",
    "    else:  \n",
    "        return text\n",
    "\n",
    "annotated_data['Preprocessed Comment'] = annotated_data['Preprocessed Comment'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to manually tokenize text including punctuations\n",
    "def custom_tokenize(text):\n",
    "    # Regex pattern to match words (including contractions) and separate punctuation\n",
    "    tokens = re.findall(r\"[\\w']+|[.,!?;]\", text)\n",
    "    return tokens\n",
    "\n",
    "# Normalize slangs and abbreviations\n",
    "def normalize_slangs_abbreviations_custom(text, slang_dict):\n",
    "    if isinstance(text, str):\n",
    "        tokens = custom_tokenize(text)\n",
    "        normalized_tokens = [slang_dict.get(token.lower(), token) for token in tokens]\n",
    "        # Reconstruct the text\n",
    "        normalized_text = ' '.join(normalized_tokens).replace(\" ,\", \",\").replace(\" .\", \".\").replace(\" !\", \"!\").replace(\" ?\", \"?\")\n",
    "        return normalized_text\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "annotated_data['Preprocessed Comment'] = annotated_data['Preprocessed Comment'].apply(lambda x: normalize_slangs_abbreviations_custom(x, abbreviations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Search Term</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Metadata</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity 2</th>\n",
       "      <th>Polarity 2</th>\n",
       "      <th>Preprocessed Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>waste</td>\n",
       "      <td>Designing products with sustainability in mind...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>{'Name': 'Angla Sicurella', 'Handle': '@AnglaS...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>designing products sustainability mind, like n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>waste</td>\n",
       "      <td>Kirby would have been a waste of time - why ev...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>{'Name': 'LisaKingWheless', 'Handle': '@Lisapc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>kirby would waste time even ask? plus adds coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>waste</td>\n",
       "      <td>I wouldn’t spend another dollar at that theate...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>{'Name': 'Sheila McSheilerton', 'Handle': '@sh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>spend another dollar theater. like buy nike gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>waste</td>\n",
       "      <td>Call them back and tell them they’re lying bec...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>{'Name': 'UncleChrissy', 'Handle': '@uncle_chr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>call back tell lying already. trying get real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>waste</td>\n",
       "      <td>I’m really sitting here going in on myself..li...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>{'Name': 'Jade ☥', 'Handle': '@jmerarity', 'Ti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>really sitting going.. like really going let b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>Louis Vuitton</td>\n",
       "      <td>Louis Vuitton</td>\n",
       "      <td>❤️❤️❤️</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>{'Likes_and_timestamp': '0 likes on 2024-01-17...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>red_heart red_heart red_heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>Tory Burch</td>\n",
       "      <td>Tory Burch</td>\n",
       "      <td>The pale pink in the 6th look is EVERYTHINGGGG...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>{'Likes_and_timestamp': '0 likes on 2023-09-16...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pale pink 6th look everythinggggg. cherry_blossom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>Yeezy</td>\n",
       "      <td>Yeezy</td>\n",
       "      <td>He said it himself this isn't the real Kanye s...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>{'Likes_and_timestamp': '0 likes on 2024-02-27...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>said n't real kanye care imposter saying face_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>Gucci</td>\n",
       "      <td>Gucci</td>\n",
       "      <td>😍😍😍</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>{'Likes_and_timestamp': '3 likes on 2023-09-23...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>smiling_face_with_heart eyes smiling_face_with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>Chanel, Miu Miu, Versace</td>\n",
       "      <td>Chanel, Miu Miu, Versace</td>\n",
       "      <td>Anyone here who can guide me</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>{'Likes_and_timestamp': '2 likes on 2024-03-10...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anyone guide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2682 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Brand               Search Term  \\\n",
       "0                         Nike                     waste   \n",
       "1                         Nike                     waste   \n",
       "2                         Nike                     waste   \n",
       "3                         Nike                     waste   \n",
       "4                         Nike                     waste   \n",
       "...                        ...                       ...   \n",
       "2678             Louis Vuitton             Louis Vuitton   \n",
       "2679                Tory Burch                Tory Burch   \n",
       "2680                     Yeezy                     Yeezy   \n",
       "2681                     Gucci                     Gucci   \n",
       "2682  Chanel, Miu Miu, Versace  Chanel, Miu Miu, Versace   \n",
       "\n",
       "                                                Comment     Source  \\\n",
       "0     Designing products with sustainability in mind...    Twitter   \n",
       "1     Kirby would have been a waste of time - why ev...    Twitter   \n",
       "2     I wouldn’t spend another dollar at that theate...    Twitter   \n",
       "3     Call them back and tell them they’re lying bec...    Twitter   \n",
       "4     I’m really sitting here going in on myself..li...    Twitter   \n",
       "...                                                 ...        ...   \n",
       "2678                                             ❤️❤️❤️  Instagram   \n",
       "2679  The pale pink in the 6th look is EVERYTHINGGGG...  Instagram   \n",
       "2680  He said it himself this isn't the real Kanye s...  Instagram   \n",
       "2681                                                😍😍😍  Instagram   \n",
       "2682                       Anyone here who can guide me  Instagram   \n",
       "\n",
       "                                               Metadata  Subjectivity  \\\n",
       "0     {'Name': 'Angla Sicurella', 'Handle': '@AnglaS...           0.0   \n",
       "1     {'Name': 'LisaKingWheless', 'Handle': '@Lisapc...           1.0   \n",
       "2     {'Name': 'Sheila McSheilerton', 'Handle': '@sh...           1.0   \n",
       "3     {'Name': 'UncleChrissy', 'Handle': '@uncle_chr...           1.0   \n",
       "4     {'Name': 'Jade ☥', 'Handle': '@jmerarity', 'Ti...           1.0   \n",
       "...                                                 ...           ...   \n",
       "2678  {'Likes_and_timestamp': '0 likes on 2024-01-17...           1.0   \n",
       "2679  {'Likes_and_timestamp': '0 likes on 2023-09-16...           1.0   \n",
       "2680  {'Likes_and_timestamp': '0 likes on 2024-02-27...           0.0   \n",
       "2681  {'Likes_and_timestamp': '3 likes on 2023-09-23...           1.0   \n",
       "2682  {'Likes_and_timestamp': '2 likes on 2024-03-10...           0.0   \n",
       "\n",
       "      Polarity  Subjectivity 2  Polarity 2  \\\n",
       "0          NaN             0.0         NaN   \n",
       "1          0.0             1.0         1.0   \n",
       "2          0.0             1.0         0.0   \n",
       "3          0.0             1.0         1.0   \n",
       "4          1.0             1.0         1.0   \n",
       "...        ...             ...         ...   \n",
       "2678       1.0             1.0         1.0   \n",
       "2679       1.0             1.0         1.0   \n",
       "2680       NaN             0.0         NaN   \n",
       "2681       1.0             1.0         1.0   \n",
       "2682       NaN             0.0         NaN   \n",
       "\n",
       "                                   Preprocessed Comment  \n",
       "0     designing products sustainability mind, like n...  \n",
       "1     kirby would waste time even ask? plus adds coa...  \n",
       "2     spend another dollar theater. like buy nike gr...  \n",
       "3     call back tell lying already. trying get real ...  \n",
       "4     really sitting going.. like really going let b...  \n",
       "...                                                 ...  \n",
       "2678                      red_heart red_heart red_heart  \n",
       "2679  pale pink 6th look everythinggggg. cherry_blossom  \n",
       "2680  said n't real kanye care imposter saying face_...  \n",
       "2681  smiling_face_with_heart eyes smiling_face_with...  \n",
       "2682                                       anyone guide  \n",
       "\n",
       "[2682 rows x 10 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHY is Hermes even getting involved at the Lotus casino, seems like a damn waste of time – tho I know they're probably trying to give Luke more backstory before the finale\n",
      "hermes even getting involved lotus casino, seems like damn waste time though know 're probably trying give luke backstory finale\n"
     ]
    }
   ],
   "source": [
    "print(annotated_data['Comment'].iloc[20])\n",
    "print(annotated_data['Preprocessed Comment'].iloc[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the number of records\n",
    "num_records = annotated_data.shape[0]\n",
    "\n",
    "# Generate 'subjectivity' column with random values of 0 or 1\\\n",
    "subjectivity_values = np.random.randint(2, size=num_records)\n",
    "\n",
    "# Generate 'polarity' column based on 'subjectivity'\n",
    "polarity_values = np.where(subjectivity_values == 0, np.nan, np.random.randint(2, size=num_records))\n",
    "\n",
    "# Create dataframe\n",
    "data = {'Subjectivity': subjectivity_values, 'Polarity': polarity_values}\n",
    "random_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5100671140939598\n",
      "Precision: 0.5930408472012103\n",
      "Recall: 0.5025641025641026\n",
      "F1-score: 0.5440666204024983\n",
      "Accuracy: 0.49165596919127086\n",
      "Precision: 0.5336658354114713\n",
      "Recall: 0.5059101654846335\n",
      "F1-score: 0.5194174757281553\n"
     ]
    }
   ],
   "source": [
    "# Convert subjectivity values to integers for comparison\n",
    "ground_truth_df = annotated_data.copy()\n",
    "\n",
    "ground_truth_df['Subjectivity'] = ground_truth_df['Subjectivity'].astype(int)\n",
    "random_df['Subjectivity'] = random_df['Subjectivity'].astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(ground_truth_df['Subjectivity'], random_df['Subjectivity'])\n",
    "precision = precision_score(ground_truth_df['Subjectivity'], random_df['Subjectivity'])\n",
    "recall = recall_score(ground_truth_df['Subjectivity'], random_df['Subjectivity'])\n",
    "f1 = f1_score(ground_truth_df['Subjectivity'], random_df['Subjectivity'])\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Drop rows with null values in the 'polarity' column for both dataframes\n",
    "ground_truth_df = annotated_data.dropna(subset=['Polarity'])\n",
    "random_df = random_df.dropna(subset=['Polarity'])\n",
    "\n",
    "# Merge dataframes on the index to align rows based on non-null values in the 'polarity' column\n",
    "merged_df = pd.merge(ground_truth_df, random_df, left_index=True, right_index=True, suffixes=('_gt', '_random'))\n",
    "\n",
    "# Calculate metrics using the merged dataframe\n",
    "accuracy = accuracy_score(merged_df['Polarity_gt'], merged_df['Polarity_random'])\n",
    "precision = precision_score(merged_df['Polarity_gt'], merged_df['Polarity_random'])\n",
    "recall = recall_score(merged_df['Polarity_gt'], merged_df['Polarity_random'])\n",
    "f1 = f1_score(merged_df['Polarity_gt'], merged_df['Polarity_random'])\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Models\n",
    "- SVM\n",
    "- Random Forest\n",
    "- Logistic Regression\n",
    "\n",
    "Features:\n",
    "- word embeddings, \n",
    "- tf-idf, \n",
    "- n-gram\n",
    "- combination of all three\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subjectivity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "word_embeddings = gensim.downloader.load('word2vec-google-news-300')\n",
    "\n",
    "# Extract comments and corresponding subjectivity labels\n",
    "comments = annotated_data['Preprocessed Comment'].tolist()\n",
    "labels = annotated_data['Subjectivity'].tolist()\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # Unigrams and bigrams\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(comments)\n",
    "\n",
    "# Convert text data to n-gram features\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))  # Unigrams and bigrams\n",
    "ngram_features = ngram_vectorizer.fit_transform(comments)\n",
    "\n",
    "# Convert each comment to a vector representation using word embeddings\n",
    "comment_vectors = []\n",
    "for comment in comments:\n",
    "    words = comment.split()\n",
    "    vectors = [word_embeddings[word] for word in words if word in word_embeddings]\n",
    "    if vectors:\n",
    "        comment_vectors.append(sum(vectors) / len(vectors))  # Average of word vectors in the comment\n",
    "    else:\n",
    "        comment_vectors.append([0] * 300)  # Use zero vector if no word found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features\n",
    "combined_features = hstack((tfidf_features, ngram_features, comment_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.6919254658385093\n",
      "Precision: 0.6885245901639344\n",
      "Recall: 0.8307692307692308\n",
      "F1-score: 0.7529880478087649\n",
      "Time taken to train SVM model: 1.8377976417541504\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.6633540372670808\n",
      "Precision: 0.652317880794702\n",
      "Recall: 0.865934065934066\n",
      "F1-score: 0.7440982058545798\n",
      "Time taken to train Random Forest model: 17.83667230606079\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.6434782608695652\n",
      "Precision: 0.6329113924050633\n",
      "Recall: 0.8791208791208791\n",
      "F1-score: 0.7359705611775529\n",
      "Time taken to train Logistic Regression model: 0.2886679172515869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost Metrics:\n",
      "Accuracy: 0.662111801242236\n",
      "Precision: 0.6631016042780749\n",
      "Recall: 0.8175824175824176\n",
      "F1-score: 0.7322834645669292\n",
      "Time taken to train AdaBoost model: 21.03068208694458\n",
      "\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.6931677018633541\n",
      "Precision: 0.7203389830508474\n",
      "Recall: 0.7472527472527473\n",
      "F1-score: 0.7335490830636462\n",
      "Time taken to train XGBoost model: 4.992202043533325\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_start_time = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1-score:\", f1_svm)\n",
    "print(\"Time taken to train SVM model:\", svm_end_time - svm_start_time)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1-score:\", f1_rf)\n",
    "print(\"Time taken to train Random Forest model:\", rf_end_time - rf_start_time)\n",
    "\n",
    "# Train logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_start_time = time.time()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log = logistic_model.predict(X_test)\n",
    "logistic_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "precision_log = precision_score(y_test, y_pred_log)\n",
    "recall_log = recall_score(y_test, y_pred_log)\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_log)\n",
    "print(\"Precision:\", precision_log)\n",
    "print(\"Recall:\", recall_log)\n",
    "print(\"F1-score:\", f1_log)\n",
    "print(\"Time taken to train Logistic Regression model:\", logistic_end_time - logistic_start_time)\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_start_time = time.time()\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "ada_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for AdaBoost\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "print(\"\\nAdaBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_ada)\n",
    "print(\"Precision:\", precision_ada)\n",
    "print(\"Recall:\", recall_ada)\n",
    "print(\"F1-score:\", f1_ada)\n",
    "print(\"Time taken to train AdaBoost model:\", ada_end_time - ada_start_time)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_start_time = time.time()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_xgb)\n",
    "print(\"Precision:\", precision_xgb)\n",
    "print(\"Recall:\", recall_xgb)\n",
    "print(\"F1-score:\", f1_xgb)\n",
    "print(\"Time taken to train XGBoost model:\", xgb_end_time - xgb_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.6745341614906832\n",
      "Precision: 0.6895874263261297\n",
      "Recall: 0.7714285714285715\n",
      "F1-score: 0.7282157676348547\n",
      "Time taken to train SVM model: 1.6357707977294922\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.6720496894409937\n",
      "Precision: 0.6672504378283712\n",
      "Recall: 0.8373626373626374\n",
      "F1-score: 0.7426900584795322\n",
      "Time taken to train Random Forest model: 18.76086449623108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.6708074534161491\n",
      "Precision: 0.685546875\n",
      "Recall: 0.7714285714285715\n",
      "F1-score: 0.7259565667011375\n",
      "Time taken to train Logistic Regression model: 1.5035247802734375\n",
      "\n",
      "AdaBoost Metrics:\n",
      "Accuracy: 0.6670807453416149\n",
      "Precision: 0.6709323583180987\n",
      "Recall: 0.8065934065934066\n",
      "F1-score: 0.7325349301397206\n",
      "Time taken to train AdaBoost model: 21.1769278049469\n",
      "\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.7167701863354037\n",
      "Precision: 0.715370018975332\n",
      "Recall: 0.8285714285714286\n",
      "F1-score: 0.7678207739307535\n",
      "Time taken to train XGBoost model: 3.929631471633911\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ngram_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_start_time = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1-score:\", f1_svm)\n",
    "print(\"Time taken to train SVM model:\", svm_end_time - svm_start_time)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1-score:\", f1_rf)\n",
    "print(\"Time taken to train Random Forest model:\", rf_end_time - rf_start_time)\n",
    "\n",
    "# Train logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_start_time = time.time()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log = logistic_model.predict(X_test)\n",
    "logistic_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "precision_log = precision_score(y_test, y_pred_log)\n",
    "recall_log = recall_score(y_test, y_pred_log)\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_log)\n",
    "print(\"Precision:\", precision_log)\n",
    "print(\"Recall:\", recall_log)\n",
    "print(\"F1-score:\", f1_log)\n",
    "print(\"Time taken to train Logistic Regression model:\", logistic_end_time - logistic_start_time)\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_start_time = time.time()\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "ada_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for AdaBoost\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "print(\"\\nAdaBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_ada)\n",
    "print(\"Precision:\", precision_ada)\n",
    "print(\"Recall:\", recall_ada)\n",
    "print(\"F1-score:\", f1_ada)\n",
    "print(\"Time taken to train AdaBoost model:\", ada_end_time - ada_start_time)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_start_time = time.time()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_xgb)\n",
    "print(\"Precision:\", precision_xgb)\n",
    "print(\"Recall:\", recall_xgb)\n",
    "print(\"F1-score:\", f1_xgb)\n",
    "print(\"Time taken to train XGBoost model:\", xgb_end_time - xgb_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.7006211180124223\n",
      "Precision: 0.7106299212598425\n",
      "Recall: 0.7934065934065934\n",
      "F1-score: 0.7497403946002077\n",
      "Time taken to train SVM model: 0.2684347629547119\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.6795031055900621\n",
      "Precision: 0.6862003780718336\n",
      "Recall: 0.7978021978021979\n",
      "F1-score: 0.7378048780487805\n",
      "Time taken to train Random Forest model: 1.7223725318908691\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.7118012422360248\n",
      "Precision: 0.7173489278752436\n",
      "Recall: 0.8087912087912088\n",
      "F1-score: 0.7603305785123967\n",
      "Time taken to train Logistic Regression model: 0.015833139419555664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost Metrics:\n",
      "Accuracy: 0.6683229813664596\n",
      "Precision: 0.6902834008097166\n",
      "Recall: 0.7494505494505495\n",
      "F1-score: 0.7186512118018967\n",
      "Time taken to train AdaBoost model: 3.066194534301758\n",
      "\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.6881987577639752\n",
      "Precision: 0.7073170731707317\n",
      "Recall: 0.7648351648351648\n",
      "F1-score: 0.7349524815205913\n",
      "Time taken to train XGBoost model: 1.2156713008880615\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(comment_vectors, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_start_time = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1-score:\", f1_svm)\n",
    "print(\"Time taken to train SVM model:\", svm_end_time - svm_start_time)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1-score:\", f1_rf)\n",
    "print(\"Time taken to train Random Forest model:\", rf_end_time - rf_start_time)\n",
    "\n",
    "# Train logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_start_time = time.time()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log = logistic_model.predict(X_test)\n",
    "logistic_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "precision_log = precision_score(y_test, y_pred_log)\n",
    "recall_log = recall_score(y_test, y_pred_log)\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_log)\n",
    "print(\"Precision:\", precision_log)\n",
    "print(\"Recall:\", recall_log)\n",
    "print(\"F1-score:\", f1_log)\n",
    "print(\"Time taken to train Logistic Regression model:\", logistic_end_time - logistic_start_time)\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_start_time = time.time()\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "ada_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for AdaBoost\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "print(\"\\nAdaBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_ada)\n",
    "print(\"Precision:\", precision_ada)\n",
    "print(\"Recall:\", recall_ada)\n",
    "print(\"F1-score:\", f1_ada)\n",
    "print(\"Time taken to train AdaBoost model:\", ada_end_time - ada_start_time)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_start_time = time.time()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_xgb)\n",
    "print(\"Precision:\", precision_xgb)\n",
    "print(\"Recall:\", recall_xgb)\n",
    "print(\"F1-score:\", f1_xgb)\n",
    "print(\"Time taken to train XGBoost model:\", xgb_end_time - xgb_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.7055900621118012\n",
      "Precision: 0.7280334728033473\n",
      "Recall: 0.7648351648351648\n",
      "F1-score: 0.7459807073954984\n",
      "Time taken to train SVM model: 5.089654207229614\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.6745341614906832\n",
      "Precision: 0.6678260869565218\n",
      "Recall: 0.843956043956044\n",
      "F1-score: 0.7456310679611651\n",
      "Time taken to train Random Forest model: 15.873722076416016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.7006211180124223\n",
      "Precision: 0.7131474103585658\n",
      "Recall: 0.7868131868131868\n",
      "F1-score: 0.7481713688610241\n",
      "Time taken to train Logistic Regression model: 2.9313454627990723\n",
      "\n",
      "AdaBoost Metrics:\n",
      "Accuracy: 0.6956521739130435\n",
      "Precision: 0.7272727272727273\n",
      "Recall: 0.7384615384615385\n",
      "F1-score: 0.732824427480916\n",
      "Time taken to train AdaBoost model: 45.2873694896698\n",
      "\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.7118012422360248\n",
      "Precision: 0.7337526205450734\n",
      "Recall: 0.7692307692307693\n",
      "F1-score: 0.7510729613733905\n",
      "Time taken to train XGBoost model: 14.095094919204712\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_start_time = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1-score:\", f1_svm)\n",
    "print(\"Time taken to train SVM model:\", svm_end_time - svm_start_time)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1-score:\", f1_rf)\n",
    "print(\"Time taken to train Random Forest model:\", rf_end_time - rf_start_time)\n",
    "\n",
    "# Train logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_start_time = time.time()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log = logistic_model.predict(X_test)\n",
    "logistic_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "precision_log = precision_score(y_test, y_pred_log)\n",
    "recall_log = recall_score(y_test, y_pred_log)\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_log)\n",
    "print(\"Precision:\", precision_log)\n",
    "print(\"Recall:\", recall_log)\n",
    "print(\"F1-score:\", f1_log)\n",
    "print(\"Time taken to train Logistic Regression model:\", logistic_end_time - logistic_start_time)\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_start_time = time.time()\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "ada_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for AdaBoost\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "print(\"\\nAdaBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_ada)\n",
    "print(\"Precision:\", precision_ada)\n",
    "print(\"Recall:\", recall_ada)\n",
    "print(\"F1-score:\", f1_ada)\n",
    "print(\"Time taken to train AdaBoost model:\", ada_end_time - ada_start_time)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_start_time = time.time()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_xgb)\n",
    "print(\"Precision:\", precision_xgb)\n",
    "print(\"Recall:\", recall_xgb)\n",
    "print(\"F1-score:\", f1_xgb)\n",
    "print(\"Time taken to train XGBoost model:\", xgb_end_time - xgb_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings consistently yield the best performance across all three models in terms of both accuracy and F1-score. This suggests that word embeddings capture the semantic meaning of words effectively, which is crucial for subjectivity detection in text data. They encode contextual information and relationships between words, potentially improving the model's ability to discern subjective content from objective content in the comments. Therefore, word embeddings seem to be the most effective feature extraction method for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Search Term</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Metadata</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity 2</th>\n",
       "      <th>Polarity 2</th>\n",
       "      <th>Preprocessed Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>waste</td>\n",
       "      <td>Kirby would have been a waste of time - why ev...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>{'Name': 'LisaKingWheless', 'Handle': '@Lisapc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>kirby would waste time even ask? plus adds coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>waste</td>\n",
       "      <td>I wouldn’t spend another dollar at that theate...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>{'Name': 'Sheila McSheilerton', 'Handle': '@sh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spend another dollar theater. like buy nike gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>waste</td>\n",
       "      <td>Call them back and tell them they’re lying bec...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>{'Name': 'UncleChrissy', 'Handle': '@uncle_chr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>call back tell lying already. trying get real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>waste</td>\n",
       "      <td>I’m really sitting here going in on myself..li...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>{'Name': 'Jade ☥', 'Handle': '@jmerarity', 'Ti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>really sitting going.. like really going let b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nike</td>\n",
       "      <td>waste</td>\n",
       "      <td>very disappointed in my new Nike  Blazer Vint...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>{'Name': 'Sailguy', 'Handle': '@NhSailguy', 'T...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disappointed new nike blazer vintage shoes. le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand Search Term                                            Comment  \\\n",
       "1  Nike       waste  Kirby would have been a waste of time - why ev...   \n",
       "2  Nike       waste  I wouldn’t spend another dollar at that theate...   \n",
       "3  Nike       waste  Call them back and tell them they’re lying bec...   \n",
       "4  Nike       waste  I’m really sitting here going in on myself..li...   \n",
       "5  Nike       waste   very disappointed in my new Nike  Blazer Vint...   \n",
       "\n",
       "    Source                                           Metadata  Subjectivity  \\\n",
       "1  Twitter  {'Name': 'LisaKingWheless', 'Handle': '@Lisapc...           1.0   \n",
       "2  Twitter  {'Name': 'Sheila McSheilerton', 'Handle': '@sh...           1.0   \n",
       "3  Twitter  {'Name': 'UncleChrissy', 'Handle': '@uncle_chr...           1.0   \n",
       "4  Twitter  {'Name': 'Jade ☥', 'Handle': '@jmerarity', 'Ti...           1.0   \n",
       "5  Twitter  {'Name': 'Sailguy', 'Handle': '@NhSailguy', 'T...           1.0   \n",
       "\n",
       "   Polarity  Subjectivity 2  Polarity 2  \\\n",
       "1       0.0               1           1   \n",
       "2       0.0               1           1   \n",
       "3       0.0               1           1   \n",
       "4       1.0               0           0   \n",
       "5       0.0               0           0   \n",
       "\n",
       "                                Preprocessed Comment  \n",
       "1  kirby would waste time even ask? plus adds coa...  \n",
       "2  spend another dollar theater. like buy nike gr...  \n",
       "3  call back tell lying already. trying get real ...  \n",
       "4  really sitting going.. like really going let b...  \n",
       "5  disappointed new nike blazer vintage shoes. le...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_polarity_data = annotated_data[annotated_data['Subjectivity']==1]\n",
    "annotated_polarity_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "word_embeddings = gensim.downloader.load('word2vec-google-news-300')\n",
    "\n",
    "# Extract comments and corresponding subjectivity labels\n",
    "comments = annotated_polarity_data['Preprocessed Comment'].tolist()\n",
    "labels = annotated_polarity_data['Polarity'].tolist()\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # Unigrams and bigrams\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(comments)\n",
    "\n",
    "# Convert text data to n-gram features\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))  # Unigrams and bigrams\n",
    "ngram_features = ngram_vectorizer.fit_transform(comments)\n",
    "\n",
    "# Convert each comment to a vector representation using word embeddings\n",
    "comment_vectors = []\n",
    "for comment in comments:\n",
    "    words = comment.split()\n",
    "    vectors = [word_embeddings[word] for word in words if word in word_embeddings]\n",
    "    if vectors:\n",
    "        comment_vectors.append(sum(vectors) / len(vectors))  # Average of word vectors in the comment\n",
    "    else:\n",
    "        comment_vectors.append([0] * 300)  # Use zero vector if no word found\n",
    "\n",
    "# Combine features\n",
    "combined_features = hstack((tfidf_features, ngram_features, comment_vectors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/tfidf_vectorizer.pkl\", 'wb') as file:\n",
    "    pickle.dump(tfidf_vectorizer, file)\n",
    "\n",
    "with open(\"models/ngram_vectorizer.pkl\", 'wb') as file:\n",
    "    pickle.dump(ngram_vectorizer, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.7393162393162394\n",
      "Precision: 0.7359154929577465\n",
      "Recall: 0.81640625\n",
      "F1-score: 0.774074074074074\n",
      "Time taken to train SVM model: 0.5085470676422119\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.688034188034188\n",
      "Precision: 0.6617647058823529\n",
      "Recall: 0.87890625\n",
      "F1-score: 0.7550335570469798\n",
      "Time taken to train Random Forest model: 6.856877326965332\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.6965811965811965\n",
      "Precision: 0.6676470588235294\n",
      "Recall: 0.88671875\n",
      "F1-score: 0.761744966442953\n",
      "Time taken to train Logistic Regression model: 0.07468438148498535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost Metrics:\n",
      "Accuracy: 0.6623931623931624\n",
      "Precision: 0.6611842105263158\n",
      "Recall: 0.78515625\n",
      "F1-score: 0.7178571428571429\n",
      "Time taken to train AdaBoost model: 8.118350982666016\n",
      "\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.7222222222222222\n",
      "Precision: 0.723404255319149\n",
      "Recall: 0.796875\n",
      "F1-score: 0.758364312267658\n",
      "Time taken to train XGBoost model: 2.1200809478759766\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_start_time = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1-score:\", f1_svm)\n",
    "print(\"Time taken to train SVM model:\", svm_end_time - svm_start_time)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1-score:\", f1_rf)\n",
    "print(\"Time taken to train Random Forest model:\", rf_end_time - rf_start_time)\n",
    "\n",
    "# Train logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_start_time = time.time()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log = logistic_model.predict(X_test)\n",
    "logistic_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "precision_log = precision_score(y_test, y_pred_log)\n",
    "recall_log = recall_score(y_test, y_pred_log)\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_log)\n",
    "print(\"Precision:\", precision_log)\n",
    "print(\"Recall:\", recall_log)\n",
    "print(\"F1-score:\", f1_log)\n",
    "print(\"Time taken to train Logistic Regression model:\", logistic_end_time - logistic_start_time)\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_start_time = time.time()\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "ada_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for AdaBoost\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "print(\"\\nAdaBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_ada)\n",
    "print(\"Precision:\", precision_ada)\n",
    "print(\"Recall:\", recall_ada)\n",
    "print(\"F1-score:\", f1_ada)\n",
    "print(\"Time taken to train AdaBoost model:\", ada_end_time - ada_start_time)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_start_time = time.time()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_xgb)\n",
    "print(\"Precision:\", precision_xgb)\n",
    "print(\"Recall:\", recall_xgb)\n",
    "print(\"F1-score:\", f1_xgb)\n",
    "print(\"Time taken to train XGBoost model:\", xgb_end_time - xgb_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.7008547008547008\n",
      "Precision: 0.7116788321167883\n",
      "Recall: 0.76171875\n",
      "F1-score: 0.7358490566037735\n",
      "Time taken to train SVM model: 0.49961090087890625\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.6837606837606838\n",
      "Precision: 0.6708860759493671\n",
      "Recall: 0.828125\n",
      "F1-score: 0.7412587412587412\n",
      "Time taken to train Random Forest model: 7.304869174957275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.7264957264957265\n",
      "Precision: 0.7424242424242424\n",
      "Recall: 0.765625\n",
      "F1-score: 0.7538461538461538\n",
      "Time taken to train Logistic Regression model: 0.7456927299499512\n",
      "\n",
      "AdaBoost Metrics:\n",
      "Accuracy: 0.6752136752136753\n",
      "Precision: 0.6710526315789473\n",
      "Recall: 0.796875\n",
      "F1-score: 0.7285714285714285\n",
      "Time taken to train AdaBoost model: 8.337119817733765\n",
      "\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.7029914529914529\n",
      "Precision: 0.7024221453287197\n",
      "Recall: 0.79296875\n",
      "F1-score: 0.744954128440367\n",
      "Time taken to train XGBoost model: 1.8524141311645508\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ngram_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_start_time = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1-score:\", f1_svm)\n",
    "print(\"Time taken to train SVM model:\", svm_end_time - svm_start_time)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1-score:\", f1_rf)\n",
    "print(\"Time taken to train Random Forest model:\", rf_end_time - rf_start_time)\n",
    "\n",
    "# Train logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_start_time = time.time()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log = logistic_model.predict(X_test)\n",
    "logistic_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "precision_log = precision_score(y_test, y_pred_log)\n",
    "recall_log = recall_score(y_test, y_pred_log)\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_log)\n",
    "print(\"Precision:\", precision_log)\n",
    "print(\"Recall:\", recall_log)\n",
    "print(\"F1-score:\", f1_log)\n",
    "print(\"Time taken to train Logistic Regression model:\", logistic_end_time - logistic_start_time)\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_start_time = time.time()\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "ada_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for AdaBoost\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "print(\"\\nAdaBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_ada)\n",
    "print(\"Precision:\", precision_ada)\n",
    "print(\"Recall:\", recall_ada)\n",
    "print(\"F1-score:\", f1_ada)\n",
    "print(\"Time taken to train AdaBoost model:\", ada_end_time - ada_start_time)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_start_time = time.time()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_xgb)\n",
    "print(\"Precision:\", precision_xgb)\n",
    "print(\"Recall:\", recall_xgb)\n",
    "print(\"F1-score:\", f1_xgb)\n",
    "print(\"Time taken to train XGBoost model:\", xgb_end_time - xgb_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.7029914529914529\n",
      "Precision: 0.7224334600760456\n",
      "Recall: 0.7421875\n",
      "F1-score: 0.7321772639691715\n",
      "Time taken to train SVM model: 0.11271905899047852\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.7115384615384616\n",
      "Precision: 0.712280701754386\n",
      "Recall: 0.79296875\n",
      "F1-score: 0.7504621072088724\n",
      "Time taken to train Random Forest model: 1.000581979751587\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.7115384615384616\n",
      "Precision: 0.7168458781362007\n",
      "Recall: 0.78125\n",
      "F1-score: 0.7476635514018691\n",
      "Time taken to train Logistic Regression model: 0.008519411087036133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost Metrics:\n",
      "Accuracy: 0.6474358974358975\n",
      "Precision: 0.6704119850187266\n",
      "Recall: 0.69921875\n",
      "F1-score: 0.6845124282982792\n",
      "Time taken to train AdaBoost model: 1.7162683010101318\n",
      "\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.7136752136752137\n",
      "Precision: 0.7420634920634921\n",
      "Recall: 0.73046875\n",
      "F1-score: 0.7362204724409449\n",
      "Time taken to train XGBoost model: 0.8052747249603271\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(comment_vectors, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_start_time = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1-score:\", f1_svm)\n",
    "print(\"Time taken to train SVM model:\", svm_end_time - svm_start_time)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1-score:\", f1_rf)\n",
    "print(\"Time taken to train Random Forest model:\", rf_end_time - rf_start_time)\n",
    "\n",
    "# Train logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_start_time = time.time()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log = logistic_model.predict(X_test)\n",
    "logistic_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "precision_log = precision_score(y_test, y_pred_log)\n",
    "recall_log = recall_score(y_test, y_pred_log)\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_log)\n",
    "print(\"Precision:\", precision_log)\n",
    "print(\"Recall:\", recall_log)\n",
    "print(\"F1-score:\", f1_log)\n",
    "print(\"Time taken to train Logistic Regression model:\", logistic_end_time - logistic_start_time)\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_start_time = time.time()\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "ada_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for AdaBoost\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "print(\"\\nAdaBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_ada)\n",
    "print(\"Precision:\", precision_ada)\n",
    "print(\"Recall:\", recall_ada)\n",
    "print(\"F1-score:\", f1_ada)\n",
    "print(\"Time taken to train AdaBoost model:\", ada_end_time - ada_start_time)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_start_time = time.time()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_xgb)\n",
    "print(\"Precision:\", precision_xgb)\n",
    "print(\"Recall:\", recall_xgb)\n",
    "print(\"F1-score:\", f1_xgb)\n",
    "print(\"Time taken to train XGBoost model:\", xgb_end_time - xgb_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.7264957264957265\n",
      "Precision: 0.7318840579710145\n",
      "Recall: 0.7890625\n",
      "F1-score: 0.7593984962406015\n",
      "Time taken to train SVM model: 1.4758880138397217\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.7136752136752137\n",
      "Precision: 0.7163120567375887\n",
      "Recall: 0.7890625\n",
      "F1-score: 0.7509293680297398\n",
      "Time taken to train Random Forest model: 8.064415454864502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Louis\\Anaconda3\\envs\\inforetrieval\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.7414529914529915\n",
      "Precision: 0.7509293680297398\n",
      "Recall: 0.7890625\n",
      "F1-score: 0.7695238095238095\n",
      "Time taken to train Logistic Regression model: 2.0073280334472656\n",
      "\n",
      "AdaBoost Metrics:\n",
      "Accuracy: 0.6944444444444444\n",
      "Precision: 0.714828897338403\n",
      "Recall: 0.734375\n",
      "F1-score: 0.7244701348747592\n",
      "Time taken to train AdaBoost model: 19.385746240615845\n",
      "\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.7200854700854701\n",
      "Precision: 0.7470355731225297\n",
      "Recall: 0.73828125\n",
      "F1-score: 0.7426326129666012\n",
      "Time taken to train XGBoost model: 7.483121633529663\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_start_time = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1-score:\", f1_svm)\n",
    "print(\"Time taken to train SVM model:\", svm_end_time - svm_start_time)\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1-score:\", f1_rf)\n",
    "print(\"Time taken to train Random Forest model:\", rf_end_time - rf_start_time)\n",
    "\n",
    "# Train logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_start_time = time.time()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log = logistic_model.predict(X_test)\n",
    "logistic_end_time = time.time()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "precision_log = precision_score(y_test, y_pred_log)\n",
    "recall_log = recall_score(y_test, y_pred_log)\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_log)\n",
    "print(\"Precision:\", precision_log)\n",
    "print(\"Recall:\", recall_log)\n",
    "print(\"F1-score:\", f1_log)\n",
    "print(\"Time taken to train Logistic Regression model:\", logistic_end_time - logistic_start_time)\n",
    "\n",
    "with open(\"models/logistic_regression_polarity.pkl\", 'wb') as file:\n",
    "    pickle.dump(logistic_model, file)\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_start_time = time.time()\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "ada_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for AdaBoost\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "print(\"\\nAdaBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_ada)\n",
    "print(\"Precision:\", precision_ada)\n",
    "print(\"Recall:\", recall_ada)\n",
    "print(\"F1-score:\", f1_ada)\n",
    "print(\"Time taken to train AdaBoost model:\", ada_end_time - ada_start_time)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_start_time = time.time()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_end_time = time.time()\n",
    "\n",
    "# Calculate metrics for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_xgb)\n",
    "print(\"Precision:\", precision_xgb)\n",
    "print(\"Recall:\", recall_xgb)\n",
    "print(\"F1-score:\", f1_xgb)\n",
    "print(\"Time taken to train XGBoost model:\", xgb_end_time - xgb_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "- For subjectivity, XGBoost with n-grams performs best (f1-score of 0.768)\n",
    "- For polarity, logistic regression with combined features performs best (f1-score of 0.769)\n",
    "\n",
    "Comment:\n",
    "- Models above are to be compared with other models investigated in other files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inforetrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
